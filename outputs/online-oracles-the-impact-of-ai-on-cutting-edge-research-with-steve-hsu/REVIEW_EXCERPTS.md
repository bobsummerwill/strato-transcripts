# Manual Review Excerpts: `online-oracles-the-impact-of-ai-on-cutting-edge-research-with-steve-hsu`

## Files present
- intermediate: `intermediates/online-oracles-the-impact-of-ai-on-cutting-edge-research-with-steve-hsu/online-oracles-the-impact-of-ai-on-cutting-edge-research-with-steve-hsu_whisperx-cloud.md`
- intermediate: `intermediates/online-oracles-the-impact-of-ai-on-cutting-edge-research-with-steve-hsu/online-oracles-the-impact-of-ai-on-cutting-edge-research-with-steve-hsu_assemblyai.md`
- output: `outputs/online-oracles-the-impact-of-ai-on-cutting-edge-research-with-steve-hsu/online-oracles-the-impact-of-ai-on-cutting-edge-research-with-steve-hsu_whisperx-cloud_opus.md`
- output: `outputs/online-oracles-the-impact-of-ai-on-cutting-edge-research-with-steve-hsu/online-oracles-the-impact-of-ai-on-cutting-edge-research-with-steve-hsu_whisperx-cloud_gemini.md`
- output: `outputs/online-oracles-the-impact-of-ai-on-cutting-edge-research-with-steve-hsu/online-oracles-the-impact-of-ai-on-cutting-edge-research-with-steve-hsu_whisperx-cloud_deepseek.md`
- output: `outputs/online-oracles-the-impact-of-ai-on-cutting-edge-research-with-steve-hsu/online-oracles-the-impact-of-ai-on-cutting-edge-research-with-steve-hsu_whisperx-cloud_chatgpt.md`
- output: `outputs/online-oracles-the-impact-of-ai-on-cutting-edge-research-with-steve-hsu/online-oracles-the-impact-of-ai-on-cutting-edge-research-with-steve-hsu_assemblyai_opus.md`
- output: `outputs/online-oracles-the-impact-of-ai-on-cutting-edge-research-with-steve-hsu/online-oracles-the-impact-of-ai-on-cutting-edge-research-with-steve-hsu_assemblyai_gemini.md`
- output: `outputs/online-oracles-the-impact-of-ai-on-cutting-edge-research-with-steve-hsu/online-oracles-the-impact-of-ai-on-cutting-edge-research-with-steve-hsu_assemblyai_deepseek.md`
- output: `outputs/online-oracles-the-impact-of-ai-on-cutting-edge-research-with-steve-hsu/online-oracles-the-impact-of-ai-on-cutting-edge-research-with-steve-hsu_assemblyai_chatgpt.md`

---

## Transcriber: `whisperx-cloud`

### Quick heuristics
- baseline words (md stripped): **6,679**
- baseline timestamps: **27** (headers=27)

- **opus**: retention=99.4%, timestamps=31/27 (×1.15), fmt_bad=0, nonmono=0, novel_CAPS=11
  - examples: Again, Amazon, Are, Claude, International Math Olympiad, Like Kieran, Put, Qwen, Qwen Max, Substack
- **gemini**: retention=99.0%, timestamps=28/27 (×1.04), fmt_bad=0, nonmono=0, novel_CAPS=13
  - examples: Amazon, Are, Bob Summerwill, Claude, Continuing, Generator, International Math Olympiad, Put, Qwen, Qwen Max
- **deepseek**: retention=99.9%, timestamps=29/27 (×1.07), fmt_bad=0, nonmono=0, novel_CAPS=0
- **chatgpt**: retention=97.3%, timestamps=31/27 (×1.15), fmt_bad=0, nonmono=0, novel_CAPS=12
  - examples: Again, Amazon, Are, Claude, Generating, International Math Olympiad, Like Kieran, Put, Qwen, Qwen Max

### Excerpts (baseline vs outputs)
#### [00:03] SPEAKER_00 (block 1/27)

**Intermediate:**

> Okay, everyone. Welcome to this very special episode of On-Chain Oracles. We are going to not cover crypto today, but cover something that I think is very interesting. Our special guest today is Steve Hsu. He is a theoretical physicist and founder of several startups, primarily on AI and genomics. Hey, Steve. How are you guys? Great to see you. We are very happy. And also, I want your help to correct the record because in our year-end review episode, I mentioned one of the exciting developments was really in AI. I mentioned that your paper that got published that you talked about getting AI assistance, but I made a mistake and I think I said it was co-authored by AI.

**opus:**

> Okay, everyone. Welcome to this very special episode of On-Chain Oracles. We are going to not cover crypto today, but cover something that I think is very interesting. Our special guest today is Steve Hsu. He is a theoretical physicist and founder of several startups, primarily on AI and genomics. Hey, Steve. How are you guys? Great to see you. We are very happy. And also, I want your help to correct the record because in our year-end review episode, I mentioned one of the exciting developments was really in AI. I mentioned that your paper that got published that you talked about getting AI assistance, but I made a mistake and I think I said it was co-authored by AI.

**gemini:**

> Okay, everyone. Welcome to this very special episode of On-Chain Oracles. We are going to not cover crypto today, but cover something that I think is very interesting. Our special guest today is Steve Hsu. He is a theoretical physicist and founder of several startups, primarily on AI and genomics. Hey, Steve. How are you guys? Great to see you. We are very happy. And also, I want your help to correct the record because in our year-end review episode, I mentioned one of the exciting developments was really in AI. I mentioned your paper that got published that you talked about getting AI assistance, but I made a mistake and I think I said it was co-authored by AI.

**deepseek:**

> Okay, everyone. Welcome to this very special episode of On-Chain Oracles. We are going to not cover crypto today, but cover something that I think is very interesting. Our special guest today is Steve Hsu. He is a theoretical physicist and founder of several startups, primarily on AI and genomics. Hey, Steve. How are you guys? Great to see you. We are very happy. And also, I want your help to correct the record because in our year-end review episode, I mentioned one of the exciting developments was really in AI. I mentioned that your paper that got published that you talked about getting AI assistance, but I made a mistake and I think I said it was co-authored by AI. But we'd like to have that clarity on what actually happened. And of course, with us, we have our usual host, Bob Summerwell, head of ecosystem. Hi there. And we've got some blurry Kieran and Jim's. Yes. Even closer. Yes. I'm confused with the backlit. We are in the same location, but in separate rooms. And so neither setup is completely optimal, but we're here. Maybe don't blur at all. Yeah, maybe don't blur. Do we know how to turn it off?

**chatgpt:**

> Okay, everyone. Welcome to this very special episode of On-Chain Oracles. We are not going to cover crypto today, but cover something that I think is very interesting. Our special guest today is Steve Hsu. He is a theoretical physicist and founder of several startups, primarily on AI and genomics. Hey, Steve. How are you guys? Great to see you. We are very happy. And also, I want your help to correct the record because, in our year-end review episode, I mentioned one of the exciting developments was really in AI. I mentioned that your paper that got published—that you talked about getting AI assistance—but I made a mistake, and I think I said it was co-authored by AI.

#### [16:32] SPEAKER_03 (block 7/27)

**Intermediate:**

> Tell everybody. Yeah. This is a very important aspect of the discussion that we haven't touched on yet, but it's very central to the main point. I think that would be useful to most listeners, which is that I didn't just use any process to get these results. OK, so when I mentioned the researcher, he's a UCLA CS professor that I interviewed who his team had gotten gold medal IMO performance from off the shelf models. They didn't just do it by making single shot one shot queries of the models. They built a whole pipeline, which their terminology and my terminology is the generator verifier architecture where you chain together or even chain parallel streams of instances of the model or one of many models, which are trying to solve the problem and proposing a solution, but then other instances that are critically evaluating what has been previously produced, finding problems with it, um, making suggestions and then you iterate. And that process, uh, the case of the brand new most recent imo problems produced five out of six correct correct proofs whereas one shot attempts with any of the top models at the time on imo problems only got maybe one out of six proofs so so you can see there's a there's a in a sense almost an order of magnitude improvement of the performance if you're willing to expend 10x or more tokens and also chained together differently prompted instances of the model or even different models, which I did. In my generator verifier chain, I was using multiple different models. I was using GPT-5. I was using Gemini. I was using Quen. So that is a process which very few people have actually experienced. So it's different from, oh, I just I put it into deep think mode or I use the most recent cloud, but I'm always doing one shot. OK, I might do a lot of reasoning, but I'm just doing one shot. Well, try chaining that together many times and don't look at any of the output till the end. at the end you might find oh i have a perfect proof of problem four on the most recent imo whereas the one shot thing that was produced is just junk right so anybody who says ai stuff is slop i have to ask them what are you talking about are you talking about the one shot product is slop or are you talking about something that at the end of a pipeline like i just described is slop because those are two very different statements and the set of people that are able to make a qualified statement about the second thing need to be one an area expert in some very deep area and number two have actually built that architecture and used it so it's almost a subset it's almost a measure of like almost zero now now co-scientist does do this co-scientist is built to have this kind of chain of generator verifier type things in it My own process has it, the UCLA thing, which is actually on GitHub. So if you want to prove some IMO, if you want to solve some Putnam or IMO problems, you can go download like their GitHub repository and work. But the point is, it's a very small set of people that have seen the maximum level of model capability. Most people have not seen the maximum level of current model capability.

**opus:**

> (No matching timestamp found in output; likely timestamp regeneration or formatting drift.)

**gemini:**

> Yeah. This is a very important aspect of the discussion that we haven't touched on yet, but it's very central to the main point. I think that would be useful to most listeners, which is that I didn't just use any process to get these results. OK, so when I mentioned the researcher, he's a UCLA CS professor that I interviewed who his team had gotten gold medal IMO performance from off the shelf models. They didn't just do it by making single shot one shot queries of the models. They built a whole pipeline, which their terminology and my terminology is the Generator-Verifier architecture where you chain together or even chain parallel streams of instances of the model or one of many models, which are trying to solve the problem and proposing a solution, but then other instances that are critically evaluating what has been previously produced, finding problems with it, making suggestions and then you iterate. And that process, the case of the brand new most recent IMO problems produced five out of six correct proofs whereas one shot attempts with any of the top models at the time on IMO problems only got maybe one out of six proofs. So you can see there's an almost an order of magnitude improvement of the performance if you're willing to expend 10x or more tokens and also chain together differently prompted instances of the model or even different models, which I did. In my Generator-Verifier chain, I was using multiple different models. I was using GPT-5. I was using Gemini. I was using Qwen. So that is a process which very few people have actually experienced. So it's different from, oh, I just I put it into deep think mode or I use the most recent Claude, but I'm always doing one shot. OK, I might do a lot of reasoning, but I'm just doing one shot. Well, try chaining that together many times and don't look at any of the output till the end. At the end you might find, oh, I have a perfect proof of problem four on the most recent IMO, whereas the one shot thing that was produced is just junk. Right. So anybody who says AI stuff is slop, I have to ask them what are you talking about? Are you talking about the one shot product is slop or are you talking about something that at the end of a pipeline like I just described is slop? Because those are two very different statements and the set of people that are able to make a qualified statement about the second thing need to be one an area expert in some very deep area and number two have actually built that architecture and used it so it's almost a subset it's almost a measure of like almost zero. Now CoScientist does do this. CoScientist is built to have this kind of chain of Generator-Verifier type things in it. My own process has it, the UCLA thing, which is actually on GitHub. So if you want to prove some IMO, if you want to solve some Putnam or IMO problems, you can go download like their GitHub repository and work. But the point is, it's a very small set of people that have seen the maximum level of model capability. Most people have not seen the maximum level of current model capability.

**deepseek:**

> (No matching timestamp found in output; likely timestamp regeneration or formatting drift.)

**chatgpt:**

> Tell everybody. Yeah. This is a very important aspect of the discussion that we haven't touched on yet, but it's very central to the main point. I think that would be useful to most listeners, which is that I didn't just use any process to get these results. Okay, so when I mentioned the researcher—he's a UCLA CS professor that I interviewed—who his team had gotten gold medal IMO performance from off-the-shelf models. They didn't just do it by making single-shot, one-shot queries of the models. They built a whole pipeline, which their terminology and my terminology is the generator-verifier architecture, where you chain together, or even chain parallel streams of instances of the model, or one of many models, which are trying to solve the problem and proposing a solution, but then other instances that are critically evaluating what has been previously produced, finding problems with it, making suggestions, and then you iterate. And that process—in the case of the brand-new, most recent IMO problems—produced five out of six correct proofs, whereas one-shot attempts with any of the top models at the time on IMO problems only got maybe one out of six proofs. So you can see there's, in a sense, almost an order-of-magnitude improvement of the performance if you're willing to expend 10x or more tokens and also chain together differently prompted instances of the model, or even different models, which I did. In my generator-verifier chain, I was using multiple different models. I was using GPT-5. I was using Gemini. I was using Qwen. So that is a process which very few people have actually experienced. So it's different from, oh, I just put it into deep think mode, or I use the most recent Claude, but I'm always doing one-shot. Okay, I might do a lot of reasoning, but I'm just doing one-shot. Well, try chaining that together many times and don't look at any of the output until the end. At the end you might find, oh, I have a perfect proof of problem four on the most recent IMO, whereas the one-shot thing that was produced is just junk, right? So anybody who says AI stuff is slop, I have to ask them, what are you talking about? Are you talking about the one-shot product is slop, or are you talking about something that at the end of a pipeline like I just described is slop? Because those are two very different statements. And the set of people that are able to make a qualified statement about the second thing need to be: one, an area expert in some very deep area; and number two, have actually built that architecture and used it. So it's almost a subset—it's almost a measure of like almost zero now. Now, CoScientist does do this. CoScientist is built to have this kind of chain of generator-verifier type things in it. My own process has it. The UCLA thing, which is actually on GitHub. So if you want to prove some IMO—if you want to solve some Putnam or IMO problems—you can go download their GitHub repository and work. But the point is, it's a very small set of people that have seen the maximum level of model capability. Most people have not seen the maximum level of current model capability.

#### [27:11] SPEAKER_02 (block 14/27)

**Intermediate:**

> But you have seen even within academic humans bubbles form too. Yeah. Well, do you mean bubbles or cycles where people just don't- I mean bubbles. I don't know if I want to put you on the record, but there are certain topics in physics, which I think you have stated. Oh, I see what you're saying. Okay. So you could have a case where everybody agrees and they're all wrong. Yeah. Yeah. And they're all magnifying. Of course, that can happen.

**opus:**

> (No matching timestamp found in output; likely timestamp regeneration or formatting drift.)

**gemini:**

> But you have seen even within academic humans bubbles form too. Yeah. Well, do you mean bubbles or cycles where people just don't- I mean bubbles. I don't know if I want to put you on the record, but there are certain topics in physics, which I think you have stated. Oh, I see what you're saying. Okay. So you could have a case where everybody agrees and they're all wrong. Yeah. Yeah. And they're all magnifying. Of course, that can happen.

**deepseek:**

> (No matching timestamp found in output; likely timestamp regeneration or formatting drift.)

**chatgpt:**

> But you have seen even within academic humans bubbles form too.

#### [31:39] SPEAKER_03 (block 21/27)

**Intermediate:**

> OK, so that was just a weird leap. Now, again, it's not a leap like Einstein jumping to special relativity, but but it was a non-trivial delta leap that I probably wouldn't have made on my own just because it wasn't it combined some stuff that I had not really thought that much about myself. put that aside that's kind of a one-off thing and just like ask the further refinements calculations i did for the paper typesetting the equations in tech all that stuff it definitely saved me weeks of work there's no question it saved me you know it definitely like a two at least a 2x speed up in how long it took to to complete the paper

**opus:**

> (No matching timestamp found in output; likely timestamp regeneration or formatting drift.)

**gemini:**

> The proposal of that set of equations, I probably never would have done myself. OK, so that was just a weird leap. Now, again, it's not a leap like Einstein jumping to special relativity, but it was a non-trivial delta leap that I probably wouldn't have made on my own just because it wasn't it combined some stuff that I had not really thought that much about myself. Put that aside, that's kind of a one-off thing and just like ask the further refinements calculations I did for the paper, typesetting the equations in TeX, all that stuff it definitely saved me weeks of work. There's no question it saved me, you know, it definitely like a 2x, at least a 2x speed up in how long it took to complete the paper.

**deepseek:**

> (No matching timestamp found in output; likely timestamp regeneration or formatting drift.)

**chatgpt:**

> Oh, yeah. I can be a little late for the—so, like, maybe we got four more minutes or five more minutes. Four more minutes. Okay. You know, like, how much time—given that you are like the first person to do this, I'm sure using the models was more cumbersome than a normal person, but what do you think the time savings was by using this model that you experienced, or the inefficiency? Was it a 2x factor, 10x factor? How do you think about that? The proposal of that set of equations, I probably never would have done myself. Okay, so that was just a weird leap. Now, again, it's not a leap like Einstein jumping to special relativity, but it was a non-trivial delta leap that I probably wouldn't have made on my own, just because it combined some stuff that I had not really thought that much about myself. Put that aside—that's kind of a one-off thing—and just ask the further refinements, calculations I did for the paper, typesetting the equations in TeX, all that stuff. It definitely saved me weeks of work. There's no question it saved me—definitely like at least a 2x speedup in how long it took to complete the paper.

#### [36:16] SPEAKER_00 (block 27/27)

**Intermediate:**

> That's incredible. So on that, I think we'll wrap up. I know you have another appointment to attend to, but thank you so much for your time. As always, where can people go to if they want to hear more of your thinking on this? If you're not already tired of me, go on X and you'll see a lot more of me, my X speed. And I have a podcast called Manifold that every two weeks I release an episode. Usually I'm interviewing somebody else. Awesome. And we'll make sure to include links of this in our notes. Thanks again, Steve. Take care. All right, guys. Make crypto great again.

**opus:**

> (No matching timestamp found in output; likely timestamp regeneration or formatting drift.)

**gemini:**

> That's incredible. So on that, I think we'll wrap up. I know you have another appointment to attend to, but thank you so much for your time. As always, where can people go to if they want to hear more of your thinking on this? If you're not already tired of me, go on X and you'll see a lot more of me, my X feed. And I have a podcast called *Manifold* that every two weeks I release an episode. Usually I'm interviewing somebody else. Awesome. And we'll make sure to include links of this in our notes. Thanks again, Steve. Take care. All right, guys. Make crypto great again.

**deepseek:**

> (No matching timestamp found in output; likely timestamp regeneration or formatting drift.)

**chatgpt:**

> That's incredible. So on that, I think we'll wrap up. I know you have another appointment to attend to, but thank you so much for your time. As always, where can people go if they want to hear more of your thinking on this?

---

## Transcriber: `assemblyai`

### Quick heuristics
- baseline words (md stripped): **6,777**
- baseline timestamps: **71** (headers=71)

- **opus**: retention=99.5%, timestamps=71/71 (×1.00), fmt_bad=0, nonmono=0, novel_CAPS=12
  - examples: And Co, Anthropic, Grok, How, International Math Olympiad, Kaplan Rajendran, Or, Qwen, Qwen Max, Rajendran
- **gemini**: retention=101.2%, timestamps=70/71 (×0.99), fmt_bad=0, nonmono=0, novel_CAPS=10
  - examples: And Co, Anthropic, Bob Summerwill, Grok, International Math Olympiad, Nirmalya, Qwen, Qwen Max, Rajendran, Substacks
- **deepseek**: retention=97.1%, timestamps=66/71 (×0.93), fmt_bad=0, nonmono=0, novel_CAPS=0
- **chatgpt**: retention=95.4%, timestamps=69/71 (×0.97), fmt_bad=0, nonmono=0, novel_CAPS=19
  - examples: And Co, Anthropic, Buy, Generating, Grok, How, In, International Math Olympiad, Kill, Look

### Excerpts (baseline vs outputs)
#### [00:03] SPEAKER_00 (block 1/71)

**Intermediate:**

> Okay everyone, welcome to this very special episode of Onchain Oracles. We are going to not cover crypto today, but cover something that I think is very interesting. Our special guest today is Steve Hsu. He is a theoretical physicist and founder of several startups primarily on AI and genomics.

**opus:**

> Okay everyone, welcome to this very special episode of Onchain Oracles. We are going to not cover crypto today, but cover something that I think is very interesting. Our special guest today is Steve Hsu. He is a theoretical physicist and founder of several startups primarily on AI and genomics.

**gemini:**

> Okay everyone, welcome to this very special episode of Onchain Oracles. We are going to not cover crypto today, but cover something that I think is very interesting. Our special guest today is Steve Hsu. He is a theoretical physicist and founder of several startups primarily on AI and genomics.

**deepseek:**

> Okay everyone, welcome to this very special episode of Onchain Oracles. We are going to not cover crypto today, but cover something that I think is very interesting. Our special guest today is Steve Hsu. He is a theoretical physicist and founder of several startups primarily on AI and genomics.

**chatgpt:**

> Okay, everyone, welcome to this very special episode of Onchain Oracles. We are not going to cover crypto today, but cover something that I think is very interesting. Our special guest today is Steve Hsu. He is a theoretical physicist and founder of several startups primarily in AI and genomics.

#### [09:52] SPEAKER_01 (block 18/71)

**Intermediate:**

> Well, aside from all the. Okay, so some people, I think actually both Nirmalia and Jonathan were predisposed to calling it AI Slop. Like if you look at the first things they wrote on their substack, they were pretty negative. And, and so we had to have back and forths about all this stuff to clarify things. There's a. I was surprised by this actually, that there's a significant chunk of the scientific community, even the physics, theoretical physics community, which I thought would have been pretty rational about this, that were predisposed toward negativity, toward viewing this as AI slob. So I didn't actually think I was taking any reputational risk because I just thought, oh, I'm going to go through this, I am going through this in good faith with the DeepMind team.

**opus:**

> Well, aside from all the, okay, so some people, I think actually both Nirmalia and Jonathan were predisposed to calling it AI slop. Like if you look at the first things they wrote on their Substack, they were pretty negative. And so we had to have back and forths about all this stuff to clarify things. There's a, I was surprised by this actually, that there's a significant chunk of the scientific community, even the physics, theoretical physics community, which I thought would have been pretty rational about this, that were predisposed toward negativity, toward viewing this as AI slop. So I didn't actually think I was taking any reputational risk because I just thought, oh, I'm going to go through this, I am going through this in good faith with the DeepMind team.

**gemini:**

> Well, aside from all the. Okay, so some people, I think actually both Nirmalya and Jonathan were predisposed to calling it AI slop. Like if you look at the first things they wrote on their Substacks, they were pretty negative. And, and so we had to have back and forths about all this stuff to clarify things. There's a. I was surprised by this actually, that there's a significant chunk of the scientific community, even the physics, theoretical physics community, which I thought would have been pretty rational about this, that were predisposed toward negativity, toward viewing this as AI slop. So I didn't actually think I was taking any reputational risk because I just thought, oh, I'm going to go through this, I am going through this in good faith with the DeepMind team.

**deepseek:**

> Well, aside from all the. Okay, so some people, I think actually both Nirmalia and Jonathan were predisposed to calling it AI Slop. Like if you look at the first things they wrote on their substack, they were pretty negative. And so we had to have back and forths about all this stuff to clarify things. There's a. I was surprised by this actually, that there's a significant chunk of the scientific community, even the physics, theoretical physics community, which I thought would have been pretty rational about this, that were predisposed toward negativity, toward viewing this as AI slob. So I didn't actually think I was taking any reputational risk because I just thought, oh, I'm going to go through this, I am going through this in good faith with the DeepMind team.

**chatgpt:**

> Well, aside from all the—okay, so some people—I think actually both Nirmalia and Jonathan were predisposed to calling it AI slop. Like, if you look at the first things they wrote on their Substack, they were pretty negative. And so we had to have back-and-forths about all this stuff to clarify things. I was surprised by this actually, that there’s a significant chunk of the scientific community, even the theoretical physics community, which I thought would have been pretty rational about this, that were predisposed toward negativity, toward viewing this as AI slop. So I didn’t actually think I was taking any reputational risk because I just thought, “Oh, I’m going to go through this. I am going through this in good faith with the DeepMind team.”

#### [25:20] SPEAKER_01 (block 36/71)

**Intermediate:**

> But yeah, I mean if you mix the models the models are very different like the Chinese models they have. You know, if you imagine this education system for 1.4 billion people in which they do a lot of testing, they have huge numbers of solved problem sets, solved problems in the Chinese educational system through college and grad school that aren't necessarily in the corpus that say anthropic or OpenAI are using to train their model. So there is some genuine independence in the detailed capabilities of the models. You don't see this so much in benchmarks because a benchmark is just one, just giant average score. But imagine you meet like a grad student came from Bulgaria and he had done all these Soviet era problems and then you meet another grad student who went to ucla. Well those two guys are going to have different gaps in their knowledge, right? So it's the same, it's the same kind of thing.

**opus:**

> But yeah, I mean if you mix the models the models are very different like the Chinese models they have, you know, if you imagine this education system for 1.4 billion people in which they do a lot of testing, they have huge numbers of solved problem sets, solved problems in the Chinese educational system through college and grad school that aren't necessarily in the corpus that say Anthropic or OpenAI are using to train their model. So there is some genuine independence in the detailed capabilities of the models. You don't see this so much in benchmarks because a benchmark is just one, just giant average score. But imagine you meet like a grad student came from Bulgaria and he had done all these Soviet era problems and then you meet another grad student who went to UCLA. Well those two guys are going to have different gaps in their knowledge, right? So it's the same, it's the same kind of thing.

**gemini:**

> But yeah, I mean if you mix the models the models are very different like the Chinese models they have. You know, if you imagine this education system for 1.4 billion people in which they do a lot of testing, they have huge numbers of solved problem sets, solved problems in the Chinese educational system through college and grad school that aren't necessarily in the corpus that say Anthropic or OpenAI are using to train their model. So there is some genuine independence in the detailed capabilities of the models. You don't see this so much in benchmarks because a benchmark is just one, just giant average score. But imagine you meet like a grad student came from Bulgaria and he had done all these Soviet era problems and then you meet another grad student who went to UCLA. Well those two guys are going to have different gaps in their knowledge, right? So it's the same, it's the same kind of thing.

**deepseek:**

> But yeah, I mean if you mix the models the models are very different like the Chinese models they have. You know, if you imagine this education system for 1.4 billion people in which they do a lot of testing, they have huge numbers of solved problem sets, solved problems in the Chinese educational system through college and grad school that aren't necessarily in the corpus that say anthropic or OpenAI are using to train their model. So there is some genuine independence in the detailed capabilities of the models. You don't see this so much in benchmarks because a benchmark is just one, just giant average score. But imagine you meet like a grad student came from Bulgaria and he had done all these Soviet era problems and then you meet another grad student who went to ucla. Well those two guys are going to have different gaps in their knowledge, right? So it's the same, it's the same kind of thing.

**chatgpt:**

> Yeah, I mean, if you mix the models, the models are very different. Like the Chinese models, they have—you know, if you imagine this education system for 1.4 billion people in which they do a lot of testing, they have huge numbers of solved problem sets, solved problems in the Chinese educational system through college and grad school, that aren’t necessarily in the corpus that, say, Anthropic or OpenAI are using to train their model. So there is some genuine independence in the detailed capabilities of the models. You don’t see this so much in benchmarks because a benchmark is just one giant average score. But imagine you meet a grad student who came from Bulgaria and he had done all these Soviet-era problems, and then you meet another grad student who went to UCLA. Well, those two guys are going to have different gaps in their knowledge, right? So it’s the same kind of thing.

#### [31:04] SPEAKER_01 (block 54/71)

**Intermediate:**

> I can be a little late for them. So, like, maybe we got four more minutes or five more minutes.

**opus:**

> I can be a little late for them. So, like, maybe we got four more minutes or five more minutes.

**gemini:**

> Oh, yeah, yeah, I can be late. I can be a little late for them. So, like, maybe we got four more minutes or five more minutes.

**deepseek:**

> I can be a little late for them. So, like, maybe we got four more minutes or five more minutes.

**chatgpt:**

> I can be a little late for them. So maybe we’ve got four more minutes or five more minutes.

#### [36:50] SPEAKER_01 (block 71/71)

**Intermediate:**

> All right, guys, make Crypto great again.

**opus:**

> All right, guys, make crypto great again.

**gemini:**

> All right, guys, make Crypto great again.

**deepseek:**

> (No matching timestamp found in output; likely timestamp regeneration or formatting drift.)

**chatgpt:**

> All right, guys. Make crypto great again.

